# TD3 Hyperparameter Configuration for Pendulum-v1

env_name: Pendulum-v1
algorithm: TD3

seed: 42
total_training_steps: 50_000
start_timesteps: 1_000   # steps before training begins (pure exploration)

# Replay Buffer
replay_buffer:
  size: 1_000_000
  batch_size: 100

# Actor Network
actor:
  learning_rate: 0.0003
  hidden_layers: [400, 300]
  activation: relu
  noise_std: 0.1       # exploration noise
  noise_type: normal

# Critic Network
critic:
  learning_rate: 0.0003
  hidden_layers: [400, 300]
  activation: relu

# Target Networks
target_network:
  tau: 0.005           # soft update rate
  policy_noise: 0.2    # added to target actions
  noise_clip: 0.5      # clip target noise

# RL Settings
discount_factor: 0.99
policy_delay: 2

# Logging and Evaluation

# Notes
notes: |
  - Using tanh in the actor output scaled by max_action.
  - Target networks initialized with main network parameters.
  - No observation normalization or reward scaling applied.
